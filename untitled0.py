# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zfSFnZxkH_TS0ABPt0fq1-shG0N6NhrE
"""

import os

os.environ['OPENAI_API_KEY'] = ''

pip install streamlit



!pip install langchain-community langchain-openai

!pip install localtunnel

!npm install -g localtunnel

!pip install unstructured

!pip install faiss-gpu-cu11==1.10.0

!pip install unstructured

!streamlit run app.py & npx localtunnel --port 8501

!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import os
# import streamlit as st
# import time
# from langchain_community.llms import OpenAI
# from langchain.chains import RetrievalQAWithSourcesChain
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_community.document_loaders import UnstructuredURLLoader
# from langchain_openai import OpenAIEmbeddings
# from langchain_community.vectorstores import FAISS # Keep FAISS import
# 
# st.title("RockyBot: News Research Tool ðŸ“ˆ")
# st.sidebar.title("News Article URLs")
# 
# urls = []
# for i in range(3):
#     url = st.sidebar.text_input(f"URL {i+1}")
#     urls.append(url)
# 
# process_url_clicked = st.sidebar.button("Process URLs")
# # Directory path to save the FAISS index
# index_dir = "faiss_index" # Changed file_path to index_dir, as we save a directory
# 
# main_placeholder = st.empty()
# llm = OpenAI(temperature=0.9, max_tokens=500)
# 
# if process_url_clicked:
#     # load data
#     loader = UnstructuredURLLoader(urls=urls)
#     main_placeholder.text("Data Loading...Started...âœ…âœ…âœ…")
#     # Check if urls is empty before loading
#     if not urls or all(url == "" for url in urls):
#         main_placeholder.text("Please provide URLs to process.")
#     else:
#         data = loader.load()
#         # split data
#         text_splitter = RecursiveCharacterTextSplitter(
#             separators=['\n\n', '\n', '.', ','],
#             chunk_size=1000
#         )
#         main_placeholder.text("Text Splitter...Started...âœ…âœ…âœ…")
#         docs = text_splitter.split_documents(data)
#         # create embeddings and save it to FAISS index
#         embeddings = OpenAIEmbeddings()
#         vectorstore_openai = FAISS.from_documents(docs, embeddings)
#         main_placeholder.text("Embedding Vector Started Building...âœ…âœ…âœ…")
#         time.sleep(2)
# 
#         # --- REPLACE PICKLE SAVE WITH FAISS save_local ---
#         # Ensure the directory for the FAISS index exists
#         if not os.path.exists(index_dir):
#             os.makedirs(index_dir)
# 
#         # Save the FAISS index using save_local
#         vectorstore_openai.save_local(index_dir)
#         main_placeholder.text(f"FAISS Index Saved Successfully to {index_dir}!âœ…âœ…âœ…")
#         # --- END REPLACEMENT ---
# 
# 
# query = main_placeholder.text_input("Question: ")
# # Check if the index directory exists
# if query:
#     if os.path.exists(index_dir): # Check for the directory, not the file
#         # --- REPLACE PICKLE LOAD WITH FAISS load_local ---
#         # Load the FAISS index using load_local
#         embeddings = OpenAIEmbeddings() # Need embeddings object to load
#         vectorstore = FAISS.load_local(index_dir, embeddings, allow_dangerous_deserialization=True) # Use allow_dangerous_deserialization if needed, but be cautious
#         # --- END REPLACEMENT ---
# 
#         chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())
#         result = chain({"question": query}, return_only_outputs=True)
#         # result will be a dictionary of this format --> {"answer": "", "sources": [] }
#         st.header("Answer")
#         st.write(result["answer"])
# 
#         # Display sources, if available
#         sources = result.get("sources", "")
#         if sources:
#             st.subheader("Sources:")
#             sources_list = sources.split("\n")  # Split the sources by newline
#             for source in sources_list:
#                 st.write(source)
#     else:
#         # Handle the case where the index hasn't been created yet
#         main_placeholder.text(f"FAISS index not found at {index_dir}. Please process URLs first.")

!streamlit run app.py & npx localtunnel --port 8501

